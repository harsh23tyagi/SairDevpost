{"ast":null,"code":"var _jsxFileName = \"/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js\";\nimport React from \"react\";\nimport axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"./Self.css\";\n\nconst videosegmentation = () => {\n  const loadAndUseBodyPix = async e => {\n    // async function loadAndUseBodyPix() {\n    e.preventDefault();\n    const net = await bodyPix.load(); // BodyPix model loaded\n\n    const imageElement = document.getElementById(\"image\");\n    console.log(\"Loaded\"); // load the BodyPix model from a checkpoint\n    // arguments for estimating person segmentation.\n\n    const outputStride = 16;\n    const segmentationThreshold = 0.5;\n    const personSegmentation = await net.estimatePersonSegmentation(imageElement, outputStride, segmentationThreshold);\n    console.log(personSegmentation);\n    console.log(\"Reached\");\n    console.log(\"Masking the image\"); // Masking the image\n\n    const segmentation = await net.estimatePersonSegmentation(imageElement);\n    const maskBackground = true; // Convert the personSegmentation into a mask to darken the background.\n\n    const backgroundDarkeningMask = bodyPix.toMaskImageData(personSegmentation, maskBackground);\n    const opacity = 0.7;\n    const canvas = document.getElementById(\"canvas\"); // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n\n    bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n  };\n\n  console.log(\"Image Masked\");\n  return React.createElement(\"div\", {\n    className: \"container\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 48\n    },\n    __self: this\n  }, React.createElement(\"form\", {\n    className: \"form\",\n    onSubmit: e => loadAndUseBodyPix(e),\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 49\n    },\n    __self: this\n  }, React.createElement(\"h1\", {\n    className: \"check\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 50\n    },\n    __self: this\n  }, \"Reached Video Segmentation Page\"), React.createElement(\"img\", {\n    src: img,\n    id: \"image\",\n    className: \"imgClass\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 51\n    },\n    __self: this\n  }), React.createElement(\"br\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 52\n    },\n    __self: this\n  }), React.createElement(\"input\", {\n    type: \"submit\",\n    className: \"btn btn-primary\",\n    value: \"Segment Image\",\n    required: true,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 53\n    },\n    __self: this\n  })), React.createElement(\"canvas\", {\n    id: \"canvas\",\n    width: \"100%\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 60\n    },\n    __self: this\n  }));\n};\n\nconsole.log(\"Hello\");\nconsole.log(\"Bigshot\");\nexport default videosegmentation;","map":{"version":3,"sources":["/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js"],"names":["React","axios","img","bodyPix","videosegmentation","loadAndUseBodyPix","e","preventDefault","net","load","imageElement","document","getElementById","console","log","outputStride","segmentationThreshold","personSegmentation","estimatePersonSegmentation","segmentation","maskBackground","backgroundDarkeningMask","toMaskImageData","opacity","canvas","drawMask"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAOC,KAAP,MAAkB,OAAlB;AACA,OAAOC,GAAP,MAAgB,cAAhB;AACA,OAAO,KAAKC,OAAZ,MAAyB,6BAAzB;AACA,OAAO,YAAP;;AACA,MAAMC,iBAAiB,GAAG,MAAM;AAC9B,QAAMC,iBAAiB,GAAG,MAAMC,CAAN,IAAW;AACnC;AACAA,IAAAA,CAAC,CAACC,cAAF;AACA,UAAMC,GAAG,GAAG,MAAML,OAAO,CAACM,IAAR,EAAlB,CAHmC,CAInC;;AACA,UAAMC,YAAY,GAAGC,QAAQ,CAACC,cAAT,CAAwB,OAAxB,CAArB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,QAAZ,EANmC,CAOnC;AAEA;;AACA,UAAMC,YAAY,GAAG,EAArB;AACA,UAAMC,qBAAqB,GAAG,GAA9B;AAEA,UAAMC,kBAAkB,GAAG,MAAMT,GAAG,CAACU,0BAAJ,CAC/BR,YAD+B,EAE/BK,YAF+B,EAG/BC,qBAH+B,CAAjC;AAKAH,IAAAA,OAAO,CAACC,GAAR,CAAYG,kBAAZ;AACAJ,IAAAA,OAAO,CAACC,GAAR,CAAY,SAAZ;AAEAD,IAAAA,OAAO,CAACC,GAAR,CAAY,mBAAZ,EArBmC,CAsBnC;;AACA,UAAMK,YAAY,GAAG,MAAMX,GAAG,CAACU,0BAAJ,CAA+BR,YAA/B,CAA3B;AAEA,UAAMU,cAAc,GAAG,IAAvB,CAzBmC,CA0BnC;;AACA,UAAMC,uBAAuB,GAAGlB,OAAO,CAACmB,eAAR,CAC9BL,kBAD8B,EAE9BG,cAF8B,CAAhC;AAKA,UAAMG,OAAO,GAAG,GAAhB;AAEA,UAAMC,MAAM,GAAGb,QAAQ,CAACC,cAAT,CAAwB,QAAxB,CAAf,CAlCmC,CAmCnC;;AACAT,IAAAA,OAAO,CAACsB,QAAR,CAAiBD,MAAjB,EAAyBd,YAAzB,EAAuCW,uBAAvC,EAAgEE,OAAhE;AACD,GArCD;;AAuCAV,EAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ;AACA,SACE;AAAK,IAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAM,IAAA,SAAS,EAAC,MAAhB;AAAuB,IAAA,QAAQ,EAAER,CAAC,IAAID,iBAAiB,CAACC,CAAD,CAAvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAI,IAAA,SAAS,EAAC,OAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCADF,EAEE;AAAK,IAAA,GAAG,EAAEJ,GAAV;AAAe,IAAA,EAAE,EAAC,OAAlB;AAA0B,IAAA,SAAS,EAAC,UAApC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAFF,EAGE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAHF,EAIE;AACE,IAAA,IAAI,EAAC,QADP;AAEE,IAAA,SAAS,EAAC,iBAFZ;AAGE,IAAA,KAAK,EAAC,eAHR;AAIE,IAAA,QAAQ,MAJV;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAJF,CADF,EAYE;AAAQ,IAAA,EAAE,EAAC,QAAX;AAAoB,IAAA,KAAK,EAAC,MAA1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAZF,CADF;AAgBD,CAzDD;;AA0DAW,OAAO,CAACC,GAAR,CAAY,OAAZ;AAEAD,OAAO,CAACC,GAAR,CAAY,SAAZ;AACA,eAAeV,iBAAf","sourcesContent":["import React from \"react\";\nimport axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"./Self.css\";\nconst videosegmentation = () => {\n  const loadAndUseBodyPix = async e => {\n    // async function loadAndUseBodyPix() {\n    e.preventDefault();\n    const net = await bodyPix.load();\n    // BodyPix model loaded\n    const imageElement = document.getElementById(\"image\");\n    console.log(\"Loaded\");\n    // load the BodyPix model from a checkpoint\n\n    // arguments for estimating person segmentation.\n    const outputStride = 16;\n    const segmentationThreshold = 0.5;\n\n    const personSegmentation = await net.estimatePersonSegmentation(\n      imageElement,\n      outputStride,\n      segmentationThreshold\n    );\n    console.log(personSegmentation);\n    console.log(\"Reached\");\n\n    console.log(\"Masking the image\");\n    // Masking the image\n    const segmentation = await net.estimatePersonSegmentation(imageElement);\n\n    const maskBackground = true;\n    // Convert the personSegmentation into a mask to darken the background.\n    const backgroundDarkeningMask = bodyPix.toMaskImageData(\n      personSegmentation,\n      maskBackground\n    );\n\n    const opacity = 0.7;\n\n    const canvas = document.getElementById(\"canvas\");\n    // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n    bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n  };\n\n  console.log(\"Image Masked\");\n  return (\n    <div className=\"container\">\n      <form className=\"form\" onSubmit={e => loadAndUseBodyPix(e)}>\n        <h1 className=\"check\">Reached Video Segmentation Page</h1>\n        <img src={img} id=\"image\" className=\"imgClass\" />\n        <br />\n        <input\n          type=\"submit\"\n          className=\"btn btn-primary\"\n          value=\"Segment Image\"\n          required\n        />\n      </form>\n      <canvas id=\"canvas\" width=\"100%\" />\n    </div>\n  );\n};\nconsole.log(\"Hello\");\n\nconsole.log(\"Bigshot\");\nexport default videosegmentation;\n"]},"metadata":{},"sourceType":"module"}
{"ast":null,"code":"var _jsxFileName = \"/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js\";\nimport React from \"react\";\nimport axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\n\nconst videosegmentation = () => {\n  return React.createElement(\"div\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 8\n    },\n    __self: this\n  }, \"Reached Video Segmentation Page\");\n};\n\nconsole.log(\"Hello\");\n\nasync function loadAndUseBodyPix() {\n  const net = await bodyPix.load(); // BodyPix model loaded\n\n  const imageElement = document.getElementById(\"image\"); // load the BodyPix model from a checkpoint\n  // arguments for estimating person segmentation.\n\n  const outputStride = 16;\n  const segmentationThreshold = 0.5;\n  const personSegmentation = await net.estimatePersonSegmentation(imageElement, outputStride, segmentationThreshold);\n  console.log(personSegmentation);\n  console.log(\"Reached\");\n}\n\nconsole.log(\"Bigshot\");\nexport default videosegmentation;","map":{"version":3,"sources":["/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js"],"names":["React","axios","img","bodyPix","videosegmentation","console","log","loadAndUseBodyPix","net","load","imageElement","document","getElementById","outputStride","segmentationThreshold","personSegmentation","estimatePersonSegmentation"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAOC,KAAP,MAAkB,OAAlB;AACA,OAAOC,GAAP,MAAgB,cAAhB;AACA,OAAO,KAAKC,OAAZ,MAAyB,6BAAzB;;AAEA,MAAMC,iBAAiB,GAAG,MAAM;AAC9B,SACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCADF;AAOD,CARD;;AASAC,OAAO,CAACC,GAAR,CAAY,OAAZ;;AACA,eAAeC,iBAAf,GAAmC;AACjC,QAAMC,GAAG,GAAG,MAAML,OAAO,CAACM,IAAR,EAAlB,CADiC,CAEjC;;AACA,QAAMC,YAAY,GAAGC,QAAQ,CAACC,cAAT,CAAwB,OAAxB,CAArB,CAHiC,CAKjC;AAEA;;AACA,QAAMC,YAAY,GAAG,EAArB;AACA,QAAMC,qBAAqB,GAAG,GAA9B;AAEA,QAAMC,kBAAkB,GAAG,MAAMP,GAAG,CAACQ,0BAAJ,CAC/BN,YAD+B,EAE/BG,YAF+B,EAG/BC,qBAH+B,CAAjC;AAKAT,EAAAA,OAAO,CAACC,GAAR,CAAYS,kBAAZ;AACAV,EAAAA,OAAO,CAACC,GAAR,CAAY,SAAZ;AACD;;AACDD,OAAO,CAACC,GAAR,CAAY,SAAZ;AACA,eAAeF,iBAAf","sourcesContent":["import React from \"react\";\nimport axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\n\nconst videosegmentation = () => {\n  return (\n    <div>\n      Reached Video Segmentation Page\n      {/* <img src={img} id=\"image\" />\n      <button>Click</button> */}\n    </div>\n  );\n};\nconsole.log(\"Hello\");\nasync function loadAndUseBodyPix() {\n  const net = await bodyPix.load();\n  // BodyPix model loaded\n  const imageElement = document.getElementById(\"image\");\n\n  // load the BodyPix model from a checkpoint\n\n  // arguments for estimating person segmentation.\n  const outputStride = 16;\n  const segmentationThreshold = 0.5;\n\n  const personSegmentation = await net.estimatePersonSegmentation(\n    imageElement,\n    outputStride,\n    segmentationThreshold\n  );\n  console.log(personSegmentation);\n  console.log(\"Reached\");\n}\nconsole.log(\"Bigshot\");\nexport default videosegmentation;\n"]},"metadata":{},"sourceType":"module"}
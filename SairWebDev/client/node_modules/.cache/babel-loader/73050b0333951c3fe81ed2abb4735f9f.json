{"ast":null,"code":"var _jsxFileName = \"/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js\";\nimport React from \"react\"; // import axios from \"axios\";\n\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"../../Self.css\"; // New Imports for videoSegmentation\n\nimport dat from \"dat.gui\";\nimport Stats from \"stats.js\"; //End of imports\n// ------Begin coding video demo------\n\nconst stats = new Stats();\nconst state = {\n  video: null,\n  strem: null,\n  net: null,\n  videoConstraints: {},\n  changingCamera: false,\n  changingArchitecture: false\n}; //Checking the type of device: Mobile or not- if mobile then android or IoS\n\nfunction isAndroid() {\n  return /Android/i.test(navigator.userAgent);\n}\n\nfunction isiOS() {\n  return /iPhone|iPad|iPod/i.test(navigator.userAgent);\n}\n\nfunction isMobile() {\n  return isAndroid() || isiOS();\n}\n\nconst getVid = async e => {\n  e.preventDefault();\n  console.log(\"Checking Devices\");\n\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n  console.log(videoDevices);\n  return videoDevices;\n}; // the below function is from the raw file\n\n\nasync function getVideoInputs() {\n  console.log(\"Checking Devices\");\n\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n  console.log(videoDevices);\n  return videoDevices;\n}\n\nfunction stopExistingVideoCapture() {\n  if (state.video && state.video.srcObject) {\n    state.video.srcObject.getTracks().forEach(track => {\n      track.stop();\n    });\n    state.video.srcObject = null;\n  }\n} // My function for the below copied function getDevideIdForLabel\n// const getDevLab = async e => {\n//   e.preventDefault();\n//   const videoInputs = await getVideoInputs();\n//   for (let i = 0; i < videoInputs.length; i++) {\n//     const videoInput = videoInputs[i];\n//     if (videoInput.label === cameraLabel) {\n//       return videoInput.deviceId;\n//     }\n//   }\n//   return null;\n// };\n\n\nasync function getDeviceIdForLabel(event, cameraLabel) {\n  event.preventDefault();\n  const videoInputs = await getVideoInputs();\n\n  for (let i = 0; i < videoInputs.length; i++) {\n    const videoInput = videoInputs[i];\n\n    if (videoInput.label === cameraLabel) {\n      return videoInput.deviceId;\n    }\n  }\n\n  return null;\n} //--------End Video Demo-------\n\n\nconst videosegmentation = () => {\n  // const loadAndUseBodyPix = async e => {\n  //   // async function loadAndUseBodyPix() {\n  //   e.preventDefault();\n  //   const net = await bodyPix.load();\n  //   // BodyPix model loaded\n  //   const imageElement = document.getElementById(\"image\");\n  //   console.log(\"Loaded\");\n  //   // load the BodyPix model from a checkpoint\n  //   // arguments for estimating person segmentation.\n  //   const outputStride = 16;\n  //   const segmentationThreshold = 0.5;\n  //   const personSegmentation = await net.estimatePersonSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(personSegmentation);\n  //   console.log(\"Reached\");\n  //   console.log(\"Masking the image\");\n  //   // Masking the image\n  //   const segmentation = await net.estimatePersonSegmentation(imageElement);\n  //   const maskBackground = true;\n  //   // Convert the personSegmentation into a mask to darken the background.\n  //   const backgroundDarkeningMask = bodyPix.toMaskImageData(\n  //     personSegmentation,\n  //     maskBackground\n  //   );\n  //   const opacity = 0.7;\n  //   const canvas = document.getElementById(\"canvas\");\n  //   // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n  //   bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n  //   console.log(\"Image Masked\");\n  //   console.log(\"Estimating Part Segmentation...\");\n  //   const partSegmentation = await net.estimatePartSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(\"Part Segmentation Results:\");\n  //   console.log(partSegmentation);\n  // };\n  return React.createElement(\"div\", {\n    className: \"container\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 157\n    },\n    __self: this\n  }, React.createElement(\"h1\", {\n    className: \"headerVidSeg\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 159\n    },\n    __self: this\n  }, \"Video Segmentation\"), React.createElement(\"form\", {\n    className: \"form\",\n    onSubmit: e => getDeviceIdForLabel(e),\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 168\n    },\n    __self: this\n  }, React.createElement(\"input\", {\n    type: \"submit\",\n    className: \"btn btn-primary\",\n    value: \"Get Device Label\",\n    required: true,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 169\n    },\n    __self: this\n  })), React.createElement(\"div\", {\n    id: \"stats\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 177\n    },\n    __self: this\n  }), React.createElement(\"div\", {\n    id: \"info\",\n    className: \"info\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 178\n    },\n    __self: this\n  }), React.createElement(\"div\", {\n    id: \"main\",\n    className: \"info\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 180\n    },\n    __self: this\n  }, React.createElement(\"video\", {\n    id: \"video\",\n    className: \"videoClass\",\n    playsInline: true,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 181\n    },\n    __self: this\n  }), React.createElement(\"canvas\", {\n    id: \"output\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 182\n    },\n    __self: this\n  })), React.createElement(\"ul\", {\n    id: \"colors\",\n    className: \"info\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 185\n    },\n    __self: this\n  }), React.createElement(\"div\", {\n    className: \"footer\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 187\n    },\n    __self: this\n  }, React.createElement(\"div\", {\n    className: \"footer-text\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 188\n    },\n    __self: this\n  }, React.createElement(\"p\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 189\n    },\n    __self: this\n  }, \"The BodyPix model can estimate which pixels in an image are part of a person, and which pixels are part of each of 24 body parts. It works on a single person, and such \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 192\n    },\n    __self: this\n  }, \"works best\"), \" when\", \" \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 193\n    },\n    __self: this\n  }, \"one person is present\"), \" in an image.\", React.createElement(\"br\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 194\n    },\n    __self: this\n  }), React.createElement(\"br\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 195\n    },\n    __self: this\n  }), \"The \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 196\n    },\n    __self: this\n  }, \"output stride\"), \" and\", \" \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 197\n    },\n    __self: this\n  }, \"model (indicated by mobileNetArchitecture)\"), \" have the largest effects on accuracy/speed. A \", React.createElement(\"i\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 198\n    },\n    __self: this\n  }, \"higher\"), \" output stride results in lower accuracy but higher speed. A \", React.createElement(\"i\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 199\n    },\n    __self: this\n  }, \"larger\"), \" model, indicated by the \", React.createElement(\"i\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 200\n    },\n    __self: this\n  }, \"mobileNetArchitecture\"), \" dropdown, results in higher accuracy but lower speed.\"), React.createElement(\"div\", {\n    className: \"footer-menu\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 203\n    },\n    __self: this\n  }, React.createElement(\"i\", {\n    className: \"material-icons switch-camera\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 204\n    },\n    __self: this\n  }, \"switch_camera\"), React.createElement(\"i\", {\n    className: \"material-icons mask mode active\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 205\n    },\n    __self: this\n  }, \"portrait\"), React.createElement(\"i\", {\n    className: \"material-icons mode bokeh\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 206\n    },\n    __self: this\n  }, \"blur_on\"), React.createElement(\"i\", {\n    className: \"material-icons mode part-map\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 207\n    },\n    __self: this\n  }, \"format_color_fill\"), React.createElement(\"i\", {\n    className: \"material-icons high-accuracy\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 208\n    },\n    __self: this\n  }, \"high_quality\")))));\n};\n\nconsole.log(\"Hello\");\nconsole.log(\"Bigshot\");\nexport default videosegmentation; // {/* <form className=\"form\" onSubmit={e => loadAndUseBodyPix(e)}>\n\n{\n  /* <h1 className=\"headerVidSeg\">Reached Video Segmentation Page</h1>\n  <div id=\"divid1\">\n  <img src={img} id=\"image\" />\n  </div>\n  <br />\n  <input\n  type=\"submit\"\n  className=\"btn btn-primary\"\n  value=\"Segment Image\"\n  required\n  />\n  </form>\n  <br />\n  <canvas id=\"canvas\" width=\"100%\" />  */\n}","map":{"version":3,"sources":["/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js"],"names":["React","img","bodyPix","dat","Stats","stats","state","video","strem","net","videoConstraints","changingCamera","changingArchitecture","isAndroid","test","navigator","userAgent","isiOS","isMobile","getVid","e","preventDefault","console","log","mediaDevices","enumerateDevices","devices","videoDevices","filter","device","kind","getVideoInputs","stopExistingVideoCapture","srcObject","getTracks","forEach","track","stop","getDeviceIdForLabel","event","cameraLabel","videoInputs","i","length","videoInput","label","deviceId","videosegmentation"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB,C,CACA;;AACA,OAAOC,GAAP,MAAgB,cAAhB;AACA,OAAO,KAAKC,OAAZ,MAAyB,6BAAzB;AACA,OAAO,gBAAP,C,CAEA;;AACA,OAAOC,GAAP,MAAgB,SAAhB;AACA,OAAOC,KAAP,MAAkB,UAAlB,C,CAEA;AAEA;;AAEA,MAAMC,KAAK,GAAG,IAAID,KAAJ,EAAd;AACA,MAAME,KAAK,GAAG;AACZC,EAAAA,KAAK,EAAE,IADK;AAEZC,EAAAA,KAAK,EAAE,IAFK;AAGZC,EAAAA,GAAG,EAAE,IAHO;AAIZC,EAAAA,gBAAgB,EAAE,EAJN;AAKZC,EAAAA,cAAc,EAAE,KALJ;AAMZC,EAAAA,oBAAoB,EAAE;AANV,CAAd,C,CASA;;AACA,SAASC,SAAT,GAAqB;AACnB,SAAO,WAAWC,IAAX,CAAgBC,SAAS,CAACC,SAA1B,CAAP;AACD;;AAED,SAASC,KAAT,GAAiB;AACf,SAAO,oBAAoBH,IAApB,CAAyBC,SAAS,CAACC,SAAnC,CAAP;AACD;;AAED,SAASE,QAAT,GAAoB;AAClB,SAAOL,SAAS,MAAMI,KAAK,EAA3B;AACD;;AAED,MAAME,MAAM,GAAG,MAAMC,CAAN,IAAW;AACxBA,EAAAA,CAAC,CAACC,cAAF;AACAC,EAAAA,OAAO,CAACC,GAAR,CAAY,kBAAZ;;AACA,MAAI,CAACR,SAAS,CAACS,YAAX,IAA2B,CAACT,SAAS,CAACS,YAAV,CAAuBC,gBAAvD,EAAyE;AACvEH,IAAAA,OAAO,CAACC,GAAR,CAAY,mCAAZ;AACA,WAAO,EAAP;AACD;;AAED,QAAMG,OAAO,GAAG,MAAMX,SAAS,CAACS,YAAV,CAAuBC,gBAAvB,EAAtB;AAEA,QAAME,YAAY,GAAGD,OAAO,CAACE,MAAR,CAAeC,MAAM,IAAIA,MAAM,CAACC,IAAP,KAAgB,YAAzC,CAArB;AACAR,EAAAA,OAAO,CAACC,GAAR,CAAYI,YAAZ;AACA,SAAOA,YAAP;AACD,CAbD,C,CAcA;;;AACA,eAAeI,cAAf,GAAgC;AAC9BT,EAAAA,OAAO,CAACC,GAAR,CAAY,kBAAZ;;AACA,MAAI,CAACR,SAAS,CAACS,YAAX,IAA2B,CAACT,SAAS,CAACS,YAAV,CAAuBC,gBAAvD,EAAyE;AACvEH,IAAAA,OAAO,CAACC,GAAR,CAAY,mCAAZ;AACA,WAAO,EAAP;AACD;;AAED,QAAMG,OAAO,GAAG,MAAMX,SAAS,CAACS,YAAV,CAAuBC,gBAAvB,EAAtB;AAEA,QAAME,YAAY,GAAGD,OAAO,CAACE,MAAR,CAAeC,MAAM,IAAIA,MAAM,CAACC,IAAP,KAAgB,YAAzC,CAArB;AACAR,EAAAA,OAAO,CAACC,GAAR,CAAYI,YAAZ;AACA,SAAOA,YAAP;AACD;;AAED,SAASK,wBAAT,GAAoC;AAClC,MAAI1B,KAAK,CAACC,KAAN,IAAeD,KAAK,CAACC,KAAN,CAAY0B,SAA/B,EAA0C;AACxC3B,IAAAA,KAAK,CAACC,KAAN,CAAY0B,SAAZ,CAAsBC,SAAtB,GAAkCC,OAAlC,CAA0CC,KAAK,IAAI;AACjDA,MAAAA,KAAK,CAACC,IAAN;AACD,KAFD;AAGA/B,IAAAA,KAAK,CAACC,KAAN,CAAY0B,SAAZ,GAAwB,IAAxB;AACD;AACF,C,CAED;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;AAEA,eAAeK,mBAAf,CAAmCC,KAAnC,EAA0CC,WAA1C,EAAuD;AACrDD,EAAAA,KAAK,CAAClB,cAAN;AACA,QAAMoB,WAAW,GAAG,MAAMV,cAAc,EAAxC;;AAEA,OAAK,IAAIW,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGD,WAAW,CAACE,MAAhC,EAAwCD,CAAC,EAAzC,EAA6C;AAC3C,UAAME,UAAU,GAAGH,WAAW,CAACC,CAAD,CAA9B;;AACA,QAAIE,UAAU,CAACC,KAAX,KAAqBL,WAAzB,EAAsC;AACpC,aAAOI,UAAU,CAACE,QAAlB;AACD;AACF;;AAED,SAAO,IAAP;AACD,C,CAED;;;AAEA,MAAMC,iBAAiB,GAAG,MAAM;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SACE;AAAK,IAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAEE;AAAI,IAAA,SAAS,EAAC,cAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAFF,EAWE;AAAM,IAAA,SAAS,EAAC,MAAhB;AAAuB,IAAA,QAAQ,EAAE3B,CAAC,IAAIkB,mBAAmB,CAAClB,CAAD,CAAzD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AACE,IAAA,IAAI,EAAC,QADP;AAEE,IAAA,SAAS,EAAC,iBAFZ;AAGE,IAAA,KAAK,EAAC,kBAHR;AAIE,IAAA,QAAQ,MAJV;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,CAXF,EAoBE;AAAK,IAAA,EAAE,EAAC,OAAR;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IApBF,EAqBE;AAAK,IAAA,EAAE,EAAC,MAAR;AAAe,IAAA,SAAS,EAAC,MAAzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IArBF,EAuBE;AAAK,IAAA,EAAE,EAAC,MAAR;AAAe,IAAA,SAAS,EAAC,MAAzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAO,IAAA,EAAE,EAAC,OAAV;AAAkB,IAAA,SAAS,EAAC,YAA5B;AAAyC,IAAA,WAAW,MAApD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,EAEE;AAAQ,IAAA,EAAE,EAAC,QAAX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAFF,CAvBF,EA4BE;AAAI,IAAA,EAAE,EAAC,QAAP;AAAgB,IAAA,SAAS,EAAC,MAA1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IA5BF,EA8BE;AAAK,IAAA,SAAS,EAAC,QAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAK,IAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iLAGqC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAHrC,WAGsE,GAHtE,EAIE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BAJF,mBAKE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IALF,EAME;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IANF,UAOM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBAPN,UAOyC,GAPzC,EAQE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDARF,qDASuC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cATvC,mEAUgD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAVhD,+BAWmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BAXnB,2DADF,EAeE;AAAK,IAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAG,IAAA,SAAS,EAAC,8BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBADF,EAEE;AAAG,IAAA,SAAS,EAAC,iCAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAFF,EAGE;AAAG,IAAA,SAAS,EAAC,2BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAHF,EAIE;AAAG,IAAA,SAAS,EAAC,8BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAJF,EAKE;AAAG,IAAA,SAAS,EAAC,8BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBALF,CAfF,CADF,CA9BF,CADF;AA4DD,CA7GD;;AA8GAE,OAAO,CAACC,GAAR,CAAY,OAAZ;AAEAD,OAAO,CAACC,GAAR,CAAY,SAAZ;AACA,eAAewB,iBAAf,C,CAEA;;AACA;AACE;;;;;;;;;;;;;;AAeD","sourcesContent":["import React from \"react\";\n// import axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"../../Self.css\";\n\n// New Imports for videoSegmentation\nimport dat from \"dat.gui\";\nimport Stats from \"stats.js\";\n\n//End of imports\n\n// ------Begin coding video demo------\n\nconst stats = new Stats();\nconst state = {\n  video: null,\n  strem: null,\n  net: null,\n  videoConstraints: {},\n  changingCamera: false,\n  changingArchitecture: false\n};\n\n//Checking the type of device: Mobile or not- if mobile then android or IoS\nfunction isAndroid() {\n  return /Android/i.test(navigator.userAgent);\n}\n\nfunction isiOS() {\n  return /iPhone|iPad|iPod/i.test(navigator.userAgent);\n}\n\nfunction isMobile() {\n  return isAndroid() || isiOS();\n}\n\nconst getVid = async e => {\n  e.preventDefault();\n  console.log(\"Checking Devices\");\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n  console.log(videoDevices);\n  return videoDevices;\n};\n// the below function is from the raw file\nasync function getVideoInputs() {\n  console.log(\"Checking Devices\");\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n  console.log(videoDevices);\n  return videoDevices;\n}\n\nfunction stopExistingVideoCapture() {\n  if (state.video && state.video.srcObject) {\n    state.video.srcObject.getTracks().forEach(track => {\n      track.stop();\n    });\n    state.video.srcObject = null;\n  }\n}\n\n// My function for the below copied function getDevideIdForLabel\n// const getDevLab = async e => {\n//   e.preventDefault();\n//   const videoInputs = await getVideoInputs();\n\n//   for (let i = 0; i < videoInputs.length; i++) {\n//     const videoInput = videoInputs[i];\n//     if (videoInput.label === cameraLabel) {\n//       return videoInput.deviceId;\n//     }\n//   }\n\n//   return null;\n// };\n\nasync function getDeviceIdForLabel(event, cameraLabel) {\n  event.preventDefault();\n  const videoInputs = await getVideoInputs();\n\n  for (let i = 0; i < videoInputs.length; i++) {\n    const videoInput = videoInputs[i];\n    if (videoInput.label === cameraLabel) {\n      return videoInput.deviceId;\n    }\n  }\n\n  return null;\n}\n\n//--------End Video Demo-------\n\nconst videosegmentation = () => {\n  // const loadAndUseBodyPix = async e => {\n  //   // async function loadAndUseBodyPix() {\n  //   e.preventDefault();\n  //   const net = await bodyPix.load();\n  //   // BodyPix model loaded\n  //   const imageElement = document.getElementById(\"image\");\n  //   console.log(\"Loaded\");\n  //   // load the BodyPix model from a checkpoint\n\n  //   // arguments for estimating person segmentation.\n  //   const outputStride = 16;\n  //   const segmentationThreshold = 0.5;\n\n  //   const personSegmentation = await net.estimatePersonSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(personSegmentation);\n  //   console.log(\"Reached\");\n\n  //   console.log(\"Masking the image\");\n  //   // Masking the image\n  //   const segmentation = await net.estimatePersonSegmentation(imageElement);\n\n  //   const maskBackground = true;\n  //   // Convert the personSegmentation into a mask to darken the background.\n  //   const backgroundDarkeningMask = bodyPix.toMaskImageData(\n  //     personSegmentation,\n  //     maskBackground\n  //   );\n\n  //   const opacity = 0.7;\n\n  //   const canvas = document.getElementById(\"canvas\");\n  //   // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n  //   bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n  //   console.log(\"Image Masked\");\n  //   console.log(\"Estimating Part Segmentation...\");\n  //   const partSegmentation = await net.estimatePartSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(\"Part Segmentation Results:\");\n  //   console.log(partSegmentation);\n  // };\n\n  return (\n    <div className=\"container\">\n      {/* --Container Begins-- */}\n      <h1 className=\"headerVidSeg\">Video Segmentation</h1>\n      {/* <form className=\"form\" onSubmit={e => getVid(e)}>\n        <input\n          type=\"submit\"\n          className=\"btn btn-primary\"\n          value=\"Check Devices\"\n          required\n        />\n      </form> */}\n      <form className=\"form\" onSubmit={e => getDeviceIdForLabel(e)}>\n        <input\n          type=\"submit\"\n          className=\"btn btn-primary\"\n          value=\"Get Device Label\"\n          required\n        />\n      </form>\n\n      <div id=\"stats\" />\n      <div id=\"info\" className=\"info\" />\n\n      <div id=\"main\" className=\"info\">\n        <video id=\"video\" className=\"videoClass\" playsInline />\n        <canvas id=\"output\" />\n      </div>\n\n      <ul id=\"colors\" className=\"info\" />\n\n      <div className=\"footer\">\n        <div className=\"footer-text\">\n          <p>\n            The BodyPix model can estimate which pixels in an image are part of\n            a person, and which pixels are part of each of 24 body parts. It\n            works on a single person, and such <strong>works best</strong> when{\" \"}\n            <strong>one person is present</strong> in an image.\n            <br />\n            <br />\n            The <strong>output stride</strong> and{\" \"}\n            <strong>model (indicated by mobileNetArchitecture)</strong> have the\n            largest effects on accuracy/speed. A <i>higher</i> output stride\n            results in lower accuracy but higher speed. A <i>larger</i> model,\n            indicated by the <i>mobileNetArchitecture</i> dropdown, results in\n            higher accuracy but lower speed.\n          </p>\n          <div className=\"footer-menu\">\n            <i className=\"material-icons switch-camera\">switch_camera</i>\n            <i className=\"material-icons mask mode active\">portrait</i>\n            <i className=\"material-icons mode bokeh\">blur_on</i>\n            <i className=\"material-icons mode part-map\">format_color_fill</i>\n            <i className=\"material-icons high-accuracy\">high_quality</i>\n          </div>\n        </div>\n      </div>\n      {/* <script src=\"videosegmentation.js\"></script> */}\n      {/* --Container Ends-- */}\n    </div>\n  );\n};\nconsole.log(\"Hello\");\n\nconsole.log(\"Bigshot\");\nexport default videosegmentation;\n\n// {/* <form className=\"form\" onSubmit={e => loadAndUseBodyPix(e)}>\n{\n  /* <h1 className=\"headerVidSeg\">Reached Video Segmentation Page</h1>\n<div id=\"divid1\">\n  <img src={img} id=\"image\" />\n</div>\n\n<br />\n<input\n  type=\"submit\"\n  className=\"btn btn-primary\"\n  value=\"Segment Image\"\n  required\n/>\n</form>\n<br />\n<canvas id=\"canvas\" width=\"100%\" />  */\n}\n"]},"metadata":{},"sourceType":"module"}
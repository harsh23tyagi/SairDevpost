{"ast":null,"code":"var _jsxFileName = \"/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js\";\nimport React from \"react\"; // import axios from \"axios\";\n\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"../../Self.css\"; // New Imports for videoSegmentation\n\nimport dat from \"dat.gui\";\nimport Stats from \"stats.js\"; //End of imports\n// ------Begin coding video demo------\n\nconst stats = new Stats();\nconst state = {\n  video: null,\n  strem: null,\n  net: null,\n  videoConstraints: {},\n  changingCamera: false,\n  changingArchitecture: false\n}; //Checking the type of device: Mobile or not- if mobile then android or IoS\n\nfunction isAndroid() {\n  return /Android/i.test(navigator.userAgent);\n}\n\nfunction isiOS() {\n  return /iPhone|iPad|iPod/i.test(navigator.userAgent);\n}\n\nfunction isMobile() {\n  return isAndroid() || isiOS();\n}\n\nconst getVid = async e => {\n  console.log(\"Checking Devices\");\n\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n  console.log(videoDevices);\n  return videoDevices;\n};\n\nasync function getVideoInputs() {\n  console.log(\"Checking Devices\");\n\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n  return videoDevices;\n} //--------End Video Demo-------\n\n\nconst videosegmentation = () => {\n  // const loadAndUseBodyPix = async e => {\n  //   // async function loadAndUseBodyPix() {\n  //   e.preventDefault();\n  //   const net = await bodyPix.load();\n  //   // BodyPix model loaded\n  //   const imageElement = document.getElementById(\"image\");\n  //   console.log(\"Loaded\");\n  //   // load the BodyPix model from a checkpoint\n  //   // arguments for estimating person segmentation.\n  //   const outputStride = 16;\n  //   const segmentationThreshold = 0.5;\n  //   const personSegmentation = await net.estimatePersonSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(personSegmentation);\n  //   console.log(\"Reached\");\n  //   console.log(\"Masking the image\");\n  //   // Masking the image\n  //   const segmentation = await net.estimatePersonSegmentation(imageElement);\n  //   const maskBackground = true;\n  //   // Convert the personSegmentation into a mask to darken the background.\n  //   const backgroundDarkeningMask = bodyPix.toMaskImageData(\n  //     personSegmentation,\n  //     maskBackground\n  //   );\n  //   const opacity = 0.7;\n  //   const canvas = document.getElementById(\"canvas\");\n  //   // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n  //   bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n  //   console.log(\"Image Masked\");\n  //   console.log(\"Estimating Part Segmentation...\");\n  //   const partSegmentation = await net.estimatePartSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(\"Part Segmentation Results:\");\n  //   console.log(partSegmentation);\n  // };\n  return React.createElement(\"div\", {\n    className: \"container\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 116\n    },\n    __self: this\n  }, React.createElement(\"h1\", {\n    className: \"headerVidSeg\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 118\n    },\n    __self: this\n  }, \"Video Segmentation\"), React.createElement(\"form\", {\n    className: \"form\",\n    onSubmit: e => getVideoInputs(e),\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 119\n    },\n    __self: this\n  }, React.createElement(\"input\", {\n    type: \"submit\",\n    className: \"btn btn-primary\",\n    value: \"Segment Image\",\n    required: true,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 120\n    },\n    __self: this\n  })), React.createElement(\"div\", {\n    id: \"stats\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 128\n    },\n    __self: this\n  }), React.createElement(\"div\", {\n    id: \"info\",\n    className: \"info\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 129\n    },\n    __self: this\n  }), React.createElement(\"div\", {\n    id: \"main\",\n    className: \"info\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 131\n    },\n    __self: this\n  }, React.createElement(\"video\", {\n    id: \"video\",\n    className: \"videoClass\",\n    playsInline: true,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 132\n    },\n    __self: this\n  }), React.createElement(\"canvas\", {\n    id: \"output\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 133\n    },\n    __self: this\n  })), React.createElement(\"ul\", {\n    id: \"colors\",\n    className: \"info\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 136\n    },\n    __self: this\n  }), React.createElement(\"div\", {\n    className: \"footer\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 138\n    },\n    __self: this\n  }, React.createElement(\"div\", {\n    className: \"footer-text\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 139\n    },\n    __self: this\n  }, React.createElement(\"p\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 140\n    },\n    __self: this\n  }, \"The BodyPix model can estimate which pixels in an image are part of a person, and which pixels are part of each of 24 body parts. It works on a single person, and such \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 143\n    },\n    __self: this\n  }, \"works best\"), \" when\", \" \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 144\n    },\n    __self: this\n  }, \"one person is present\"), \" in an image.\", React.createElement(\"br\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 145\n    },\n    __self: this\n  }), React.createElement(\"br\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 146\n    },\n    __self: this\n  }), \"The \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 147\n    },\n    __self: this\n  }, \"output stride\"), \" and\", \" \", React.createElement(\"strong\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 148\n    },\n    __self: this\n  }, \"model (indicated by mobileNetArchitecture)\"), \" have the largest effects on accuracy/speed. A \", React.createElement(\"i\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 149\n    },\n    __self: this\n  }, \"higher\"), \" output stride results in lower accuracy but higher speed. A \", React.createElement(\"i\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 150\n    },\n    __self: this\n  }, \"larger\"), \" model, indicated by the \", React.createElement(\"i\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 151\n    },\n    __self: this\n  }, \"mobileNetArchitecture\"), \" dropdown, results in higher accuracy but lower speed.\"), React.createElement(\"div\", {\n    className: \"footer-menu\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 154\n    },\n    __self: this\n  }, React.createElement(\"i\", {\n    className: \"material-icons switch-camera\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 155\n    },\n    __self: this\n  }, \"switch_camera\"), React.createElement(\"i\", {\n    className: \"material-icons mask mode active\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 156\n    },\n    __self: this\n  }, \"portrait\"), React.createElement(\"i\", {\n    className: \"material-icons mode bokeh\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 157\n    },\n    __self: this\n  }, \"blur_on\"), React.createElement(\"i\", {\n    className: \"material-icons mode part-map\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 158\n    },\n    __self: this\n  }, \"format_color_fill\"), React.createElement(\"i\", {\n    className: \"material-icons high-accuracy\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 159\n    },\n    __self: this\n  }, \"high_quality\")))));\n};\n\nconsole.log(\"Hello\");\nconsole.log(\"Bigshot\");\nexport default videosegmentation; // {/* <form className=\"form\" onSubmit={e => loadAndUseBodyPix(e)}>\n\n{\n  /* <h1 className=\"headerVidSeg\">Reached Video Segmentation Page</h1>\n  <div id=\"divid1\">\n  <img src={img} id=\"image\" />\n  </div>\n  <br />\n  <input\n  type=\"submit\"\n  className=\"btn btn-primary\"\n  value=\"Segment Image\"\n  required\n  />\n  </form>\n  <br />\n  <canvas id=\"canvas\" width=\"100%\" />  */\n}","map":{"version":3,"sources":["/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js"],"names":["React","img","bodyPix","dat","Stats","stats","state","video","strem","net","videoConstraints","changingCamera","changingArchitecture","isAndroid","test","navigator","userAgent","isiOS","isMobile","getVid","e","console","log","mediaDevices","enumerateDevices","devices","videoDevices","filter","device","kind","getVideoInputs","videosegmentation"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB,C,CACA;;AACA,OAAOC,GAAP,MAAgB,cAAhB;AACA,OAAO,KAAKC,OAAZ,MAAyB,6BAAzB;AACA,OAAO,gBAAP,C,CAEA;;AACA,OAAOC,GAAP,MAAgB,SAAhB;AACA,OAAOC,KAAP,MAAkB,UAAlB,C,CAEA;AAEA;;AAEA,MAAMC,KAAK,GAAG,IAAID,KAAJ,EAAd;AACA,MAAME,KAAK,GAAG;AACZC,EAAAA,KAAK,EAAE,IADK;AAEZC,EAAAA,KAAK,EAAE,IAFK;AAGZC,EAAAA,GAAG,EAAE,IAHO;AAIZC,EAAAA,gBAAgB,EAAE,EAJN;AAKZC,EAAAA,cAAc,EAAE,KALJ;AAMZC,EAAAA,oBAAoB,EAAE;AANV,CAAd,C,CASA;;AACA,SAASC,SAAT,GAAqB;AACnB,SAAO,WAAWC,IAAX,CAAgBC,SAAS,CAACC,SAA1B,CAAP;AACD;;AAED,SAASC,KAAT,GAAiB;AACf,SAAO,oBAAoBH,IAApB,CAAyBC,SAAS,CAACC,SAAnC,CAAP;AACD;;AAED,SAASE,QAAT,GAAoB;AAClB,SAAOL,SAAS,MAAMI,KAAK,EAA3B;AACD;;AAED,MAAME,MAAM,GAAG,MAAMC,CAAN,IAAW;AACxBC,EAAAA,OAAO,CAACC,GAAR,CAAY,kBAAZ;;AACA,MAAI,CAACP,SAAS,CAACQ,YAAX,IAA2B,CAACR,SAAS,CAACQ,YAAV,CAAuBC,gBAAvD,EAAyE;AACvEH,IAAAA,OAAO,CAACC,GAAR,CAAY,mCAAZ;AACA,WAAO,EAAP;AACD;;AAED,QAAMG,OAAO,GAAG,MAAMV,SAAS,CAACQ,YAAV,CAAuBC,gBAAvB,EAAtB;AAEA,QAAME,YAAY,GAAGD,OAAO,CAACE,MAAR,CAAeC,MAAM,IAAIA,MAAM,CAACC,IAAP,KAAgB,YAAzC,CAArB;AACAR,EAAAA,OAAO,CAACC,GAAR,CAAYI,YAAZ;AACA,SAAOA,YAAP;AACD,CAZD;;AAaA,eAAeI,cAAf,GAAgC;AAC9BT,EAAAA,OAAO,CAACC,GAAR,CAAY,kBAAZ;;AACA,MAAI,CAACP,SAAS,CAACQ,YAAX,IAA2B,CAACR,SAAS,CAACQ,YAAV,CAAuBC,gBAAvD,EAAyE;AACvEH,IAAAA,OAAO,CAACC,GAAR,CAAY,mCAAZ;AACA,WAAO,EAAP;AACD;;AAED,QAAMG,OAAO,GAAG,MAAMV,SAAS,CAACQ,YAAV,CAAuBC,gBAAvB,EAAtB;AAEA,QAAME,YAAY,GAAGD,OAAO,CAACE,MAAR,CAAeC,MAAM,IAAIA,MAAM,CAACC,IAAP,KAAgB,YAAzC,CAArB;AAEA,SAAOH,YAAP;AACD,C,CACD;;;AAEA,MAAMK,iBAAiB,GAAG,MAAM;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SACE;AAAK,IAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAEE;AAAI,IAAA,SAAS,EAAC,cAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAFF,EAGE;AAAM,IAAA,SAAS,EAAC,MAAhB;AAAuB,IAAA,QAAQ,EAAEX,CAAC,IAAIU,cAAc,CAACV,CAAD,CAApD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AACE,IAAA,IAAI,EAAC,QADP;AAEE,IAAA,SAAS,EAAC,iBAFZ;AAGE,IAAA,KAAK,EAAC,eAHR;AAIE,IAAA,QAAQ,MAJV;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,CAHF,EAYE;AAAK,IAAA,EAAE,EAAC,OAAR;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAZF,EAaE;AAAK,IAAA,EAAE,EAAC,MAAR;AAAe,IAAA,SAAS,EAAC,MAAzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAbF,EAeE;AAAK,IAAA,EAAE,EAAC,MAAR;AAAe,IAAA,SAAS,EAAC,MAAzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAO,IAAA,EAAE,EAAC,OAAV;AAAkB,IAAA,SAAS,EAAC,YAA5B;AAAyC,IAAA,WAAW,MAApD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,EAEE;AAAQ,IAAA,EAAE,EAAC,QAAX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAFF,CAfF,EAoBE;AAAI,IAAA,EAAE,EAAC,QAAP;AAAgB,IAAA,SAAS,EAAC,MAA1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IApBF,EAsBE;AAAK,IAAA,SAAS,EAAC,QAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAK,IAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iLAGqC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAHrC,WAGsE,GAHtE,EAIE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BAJF,mBAKE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IALF,EAME;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IANF,UAOM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBAPN,UAOyC,GAPzC,EAQE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDARF,qDASuC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cATvC,mEAUgD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAVhD,+BAWmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BAXnB,2DADF,EAeE;AAAK,IAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAG,IAAA,SAAS,EAAC,8BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBADF,EAEE;AAAG,IAAA,SAAS,EAAC,iCAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAFF,EAGE;AAAG,IAAA,SAAS,EAAC,2BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAHF,EAIE;AAAG,IAAA,SAAS,EAAC,8BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAJF,EAKE;AAAG,IAAA,SAAS,EAAC,8BAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBALF,CAfF,CADF,CAtBF,CADF;AAoDD,CArGD;;AAsGAC,OAAO,CAACC,GAAR,CAAY,OAAZ;AAEAD,OAAO,CAACC,GAAR,CAAY,SAAZ;AACA,eAAeS,iBAAf,C,CAEA;;AACA;AACE;;;;;;;;;;;;;;AAeD","sourcesContent":["import React from \"react\";\n// import axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"../../Self.css\";\n\n// New Imports for videoSegmentation\nimport dat from \"dat.gui\";\nimport Stats from \"stats.js\";\n\n//End of imports\n\n// ------Begin coding video demo------\n\nconst stats = new Stats();\nconst state = {\n  video: null,\n  strem: null,\n  net: null,\n  videoConstraints: {},\n  changingCamera: false,\n  changingArchitecture: false\n};\n\n//Checking the type of device: Mobile or not- if mobile then android or IoS\nfunction isAndroid() {\n  return /Android/i.test(navigator.userAgent);\n}\n\nfunction isiOS() {\n  return /iPhone|iPad|iPod/i.test(navigator.userAgent);\n}\n\nfunction isMobile() {\n  return isAndroid() || isiOS();\n}\n\nconst getVid = async e => {\n  console.log(\"Checking Devices\");\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n  console.log(videoDevices);\n  return videoDevices;\n};\nasync function getVideoInputs() {\n  console.log(\"Checking Devices\");\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [];\n  }\n\n  const devices = await navigator.mediaDevices.enumerateDevices();\n\n  const videoDevices = devices.filter(device => device.kind === \"videoinput\");\n\n  return videoDevices;\n}\n//--------End Video Demo-------\n\nconst videosegmentation = () => {\n  // const loadAndUseBodyPix = async e => {\n  //   // async function loadAndUseBodyPix() {\n  //   e.preventDefault();\n  //   const net = await bodyPix.load();\n  //   // BodyPix model loaded\n  //   const imageElement = document.getElementById(\"image\");\n  //   console.log(\"Loaded\");\n  //   // load the BodyPix model from a checkpoint\n\n  //   // arguments for estimating person segmentation.\n  //   const outputStride = 16;\n  //   const segmentationThreshold = 0.5;\n\n  //   const personSegmentation = await net.estimatePersonSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(personSegmentation);\n  //   console.log(\"Reached\");\n\n  //   console.log(\"Masking the image\");\n  //   // Masking the image\n  //   const segmentation = await net.estimatePersonSegmentation(imageElement);\n\n  //   const maskBackground = true;\n  //   // Convert the personSegmentation into a mask to darken the background.\n  //   const backgroundDarkeningMask = bodyPix.toMaskImageData(\n  //     personSegmentation,\n  //     maskBackground\n  //   );\n\n  //   const opacity = 0.7;\n\n  //   const canvas = document.getElementById(\"canvas\");\n  //   // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n  //   bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n  //   console.log(\"Image Masked\");\n  //   console.log(\"Estimating Part Segmentation...\");\n  //   const partSegmentation = await net.estimatePartSegmentation(\n  //     imageElement,\n  //     outputStride,\n  //     segmentationThreshold\n  //   );\n  //   console.log(\"Part Segmentation Results:\");\n  //   console.log(partSegmentation);\n  // };\n\n  return (\n    <div className=\"container\">\n      {/* --Container Begins-- */}\n      <h1 className=\"headerVidSeg\">Video Segmentation</h1>\n      <form className=\"form\" onSubmit={e => getVideoInputs(e)}>\n        <input\n          type=\"submit\"\n          className=\"btn btn-primary\"\n          value=\"Segment Image\"\n          required\n        />\n      </form>\n\n      <div id=\"stats\" />\n      <div id=\"info\" className=\"info\" />\n\n      <div id=\"main\" className=\"info\">\n        <video id=\"video\" className=\"videoClass\" playsInline />\n        <canvas id=\"output\" />\n      </div>\n\n      <ul id=\"colors\" className=\"info\" />\n\n      <div className=\"footer\">\n        <div className=\"footer-text\">\n          <p>\n            The BodyPix model can estimate which pixels in an image are part of\n            a person, and which pixels are part of each of 24 body parts. It\n            works on a single person, and such <strong>works best</strong> when{\" \"}\n            <strong>one person is present</strong> in an image.\n            <br />\n            <br />\n            The <strong>output stride</strong> and{\" \"}\n            <strong>model (indicated by mobileNetArchitecture)</strong> have the\n            largest effects on accuracy/speed. A <i>higher</i> output stride\n            results in lower accuracy but higher speed. A <i>larger</i> model,\n            indicated by the <i>mobileNetArchitecture</i> dropdown, results in\n            higher accuracy but lower speed.\n          </p>\n          <div className=\"footer-menu\">\n            <i className=\"material-icons switch-camera\">switch_camera</i>\n            <i className=\"material-icons mask mode active\">portrait</i>\n            <i className=\"material-icons mode bokeh\">blur_on</i>\n            <i className=\"material-icons mode part-map\">format_color_fill</i>\n            <i className=\"material-icons high-accuracy\">high_quality</i>\n          </div>\n        </div>\n      </div>\n      {/* <script src=\"videosegmentation.js\"></script> */}\n      {/* --Container Ends-- */}\n    </div>\n  );\n};\nconsole.log(\"Hello\");\n\nconsole.log(\"Bigshot\");\nexport default videosegmentation;\n\n// {/* <form className=\"form\" onSubmit={e => loadAndUseBodyPix(e)}>\n{\n  /* <h1 className=\"headerVidSeg\">Reached Video Segmentation Page</h1>\n<div id=\"divid1\">\n  <img src={img} id=\"image\" />\n</div>\n\n<br />\n<input\n  type=\"submit\"\n  className=\"btn btn-primary\"\n  value=\"Segment Image\"\n  required\n/>\n</form>\n<br />\n<canvas id=\"canvas\" width=\"100%\" />  */\n}\n"]},"metadata":{},"sourceType":"module"}
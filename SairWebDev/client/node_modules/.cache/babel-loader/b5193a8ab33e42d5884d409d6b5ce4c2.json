{"ast":null,"code":"var _jsxFileName = \"/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js\";\nimport React from \"react\";\nimport axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"../../Self.css\";\n\nconst videosegmentation = () => {\n  const loadAndUseBodyPix = async e => {\n    // async function loadAndUseBodyPix() {\n    e.preventDefault();\n    const net = await bodyPix.load(); // BodyPix model loaded\n\n    const imageElement = document.getElementById(\"image\");\n    console.log(\"Loaded\"); // load the BodyPix model from a checkpoint\n    // arguments for estimating person segmentation.\n\n    const outputStride = 16;\n    const segmentationThreshold = 0.5;\n    const personSegmentation = await net.estimatePersonSegmentation(imageElement, outputStride, segmentationThreshold);\n    console.log(personSegmentation);\n    console.log(\"Reached\");\n    console.log(\"Masking the image\"); // Masking the image\n\n    const segmentation = await net.estimatePersonSegmentation(imageElement);\n    const maskBackground = true; // Convert the personSegmentation into a mask to darken the background.\n\n    const backgroundDarkeningMask = bodyPix.toMaskImageData(personSegmentation, maskBackground);\n    const opacity = 0.7;\n    const canvas = document.getElementById(\"canvas\"); // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n\n    bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n    console.log(\"Image Masked\");\n    console.log(\"Estimating Part Segmentation...\");\n    const partSegmentation = await net.estimatePartSegmentation(imageElement, outputStride, segmentationThreshold);\n    console.log(\"Part Segmentation Results:\");\n    console.log(partSegmentation);\n  };\n\n  return React.createElement(\"div\", {\n    className: \"container\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 56\n    },\n    __self: this\n  }, React.createElement(\"h1\", {\n    className: \"headerVidSeg\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 57\n    },\n    __self: this\n  }, \"Video Segmentation\"));\n};\n\nconsole.log(\"Hello\");\nconsole.log(\"Bigshot\");\nexport default videosegmentation;","map":{"version":3,"sources":["/Users/harshtyagi/Documents/Sair/React2/Middleware/client/src/components/videosegmentation/videosegmentation.js"],"names":["React","axios","img","bodyPix","videosegmentation","loadAndUseBodyPix","e","preventDefault","net","load","imageElement","document","getElementById","console","log","outputStride","segmentationThreshold","personSegmentation","estimatePersonSegmentation","segmentation","maskBackground","backgroundDarkeningMask","toMaskImageData","opacity","canvas","drawMask","partSegmentation","estimatePartSegmentation"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAOC,KAAP,MAAkB,OAAlB;AACA,OAAOC,GAAP,MAAgB,cAAhB;AACA,OAAO,KAAKC,OAAZ,MAAyB,6BAAzB;AACA,OAAO,gBAAP;;AACA,MAAMC,iBAAiB,GAAG,MAAM;AAC9B,QAAMC,iBAAiB,GAAG,MAAMC,CAAN,IAAW;AACnC;AACAA,IAAAA,CAAC,CAACC,cAAF;AACA,UAAMC,GAAG,GAAG,MAAML,OAAO,CAACM,IAAR,EAAlB,CAHmC,CAInC;;AACA,UAAMC,YAAY,GAAGC,QAAQ,CAACC,cAAT,CAAwB,OAAxB,CAArB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,QAAZ,EANmC,CAOnC;AAEA;;AACA,UAAMC,YAAY,GAAG,EAArB;AACA,UAAMC,qBAAqB,GAAG,GAA9B;AAEA,UAAMC,kBAAkB,GAAG,MAAMT,GAAG,CAACU,0BAAJ,CAC/BR,YAD+B,EAE/BK,YAF+B,EAG/BC,qBAH+B,CAAjC;AAKAH,IAAAA,OAAO,CAACC,GAAR,CAAYG,kBAAZ;AACAJ,IAAAA,OAAO,CAACC,GAAR,CAAY,SAAZ;AAEAD,IAAAA,OAAO,CAACC,GAAR,CAAY,mBAAZ,EArBmC,CAsBnC;;AACA,UAAMK,YAAY,GAAG,MAAMX,GAAG,CAACU,0BAAJ,CAA+BR,YAA/B,CAA3B;AAEA,UAAMU,cAAc,GAAG,IAAvB,CAzBmC,CA0BnC;;AACA,UAAMC,uBAAuB,GAAGlB,OAAO,CAACmB,eAAR,CAC9BL,kBAD8B,EAE9BG,cAF8B,CAAhC;AAKA,UAAMG,OAAO,GAAG,GAAhB;AAEA,UAAMC,MAAM,GAAGb,QAAQ,CAACC,cAAT,CAAwB,QAAxB,CAAf,CAlCmC,CAmCnC;;AACAT,IAAAA,OAAO,CAACsB,QAAR,CAAiBD,MAAjB,EAAyBd,YAAzB,EAAuCW,uBAAvC,EAAgEE,OAAhE;AACAV,IAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ;AACAD,IAAAA,OAAO,CAACC,GAAR,CAAY,iCAAZ;AACA,UAAMY,gBAAgB,GAAG,MAAMlB,GAAG,CAACmB,wBAAJ,CAC7BjB,YAD6B,EAE7BK,YAF6B,EAG7BC,qBAH6B,CAA/B;AAKAH,IAAAA,OAAO,CAACC,GAAR,CAAY,4BAAZ;AACAD,IAAAA,OAAO,CAACC,GAAR,CAAYY,gBAAZ;AACD,GA9CD;;AAgDA,SACE;AAAK,IAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAI,IAAA,SAAS,EAAC,cAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BADF,CADF;AAqBD,CAtED;;AAuEAb,OAAO,CAACC,GAAR,CAAY,OAAZ;AAEAD,OAAO,CAACC,GAAR,CAAY,SAAZ;AACA,eAAeV,iBAAf","sourcesContent":["import React from \"react\";\nimport axios from \"axios\";\nimport img from \"./image1.jpg\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport \"../../Self.css\";\nconst videosegmentation = () => {\n  const loadAndUseBodyPix = async e => {\n    // async function loadAndUseBodyPix() {\n    e.preventDefault();\n    const net = await bodyPix.load();\n    // BodyPix model loaded\n    const imageElement = document.getElementById(\"image\");\n    console.log(\"Loaded\");\n    // load the BodyPix model from a checkpoint\n\n    // arguments for estimating person segmentation.\n    const outputStride = 16;\n    const segmentationThreshold = 0.5;\n\n    const personSegmentation = await net.estimatePersonSegmentation(\n      imageElement,\n      outputStride,\n      segmentationThreshold\n    );\n    console.log(personSegmentation);\n    console.log(\"Reached\");\n\n    console.log(\"Masking the image\");\n    // Masking the image\n    const segmentation = await net.estimatePersonSegmentation(imageElement);\n\n    const maskBackground = true;\n    // Convert the personSegmentation into a mask to darken the background.\n    const backgroundDarkeningMask = bodyPix.toMaskImageData(\n      personSegmentation,\n      maskBackground\n    );\n\n    const opacity = 0.7;\n\n    const canvas = document.getElementById(\"canvas\");\n    // draw the mask onto the image on a canvas.  With opacity set to 0.7 this will darken the background.\n    bodyPix.drawMask(canvas, imageElement, backgroundDarkeningMask, opacity);\n    console.log(\"Image Masked\");\n    console.log(\"Estimating Part Segmentation...\");\n    const partSegmentation = await net.estimatePartSegmentation(\n      imageElement,\n      outputStride,\n      segmentationThreshold\n    );\n    console.log(\"Part Segmentation Results:\");\n    console.log(partSegmentation);\n  };\n\n  return (\n    <div className=\"container\">\n      <h1 className=\"headerVidSeg\">Video Segmentation</h1>\n      {/* <form className=\"form\" onSubmit={e => loadAndUseBodyPix(e)}>\n        <h1 className=\"headerVidSeg\">Reached Video Segmentation Page</h1>\n        <div id=\"divid1\">\n          <img src={img} id=\"image\" />\n        </div>\n\n        <br />\n        <input\n          type=\"submit\"\n          className=\"btn btn-primary\"\n          value=\"Segment Image\"\n          required\n        />\n      </form>\n      <br />\n      <canvas id=\"canvas\" width=\"100%\" /> */}\n    </div>\n  );\n};\nconsole.log(\"Hello\");\n\nconsole.log(\"Bigshot\");\nexport default videosegmentation;\n"]},"metadata":{},"sourceType":"module"}